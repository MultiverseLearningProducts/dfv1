<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">


		<!-- SEO -->
    <title>Multiverse Advanced Techniques Session 1</title>
    <meta name="description" content="In this session we will be examing some of the more advanced topics that will be coming up in your KM1 exam.">
    <link rel="shortcut icon" type="image/x-icon" href="../assets/multiverse_brand/Logo/01_Deep Space/PNG/Multiverse_Symbol_RGB_Navy.png">
    <!-- URL CANONICAL -->
    <!-- <link rel="canonical" href="http://your-url.com/permalink"> -->

		<link rel="stylesheet" href="../Dependencies/dist/reveal.css">
		<link rel="stylesheet" href="../Dependencies/dist/reset.css">
    <link rel="stylesheet" href="../Dependencies/css/mv.css">
		<link rel="stylesheet" href="//codemirror.net/lib/codemirror.css">
    <script src="//codemirror.net/addon/runmode/runmode-standalone.js"></script>
    <script src="//codemirror.net/mode/python/python.js"></script>


		
		<!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Roboto:100,100i,300,300i,400,400i,700,700i%7CMaitree:200,300,400,600,700&amp;subset=latin-ext" rel="stylesheet">

    <!-- CSS Base -->
    <link rel="stylesheet" type='text/css' media='all' href="../Dependencies/static/css/webslides.css">

    <!-- Optional - CSS SVG Icons (Font Awesome) -->
    <link rel="stylesheet" type="text/css" media="all" href="../Dependencies/static/css/svg-icons.css">
    <!-- Android -->
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="theme-color" content="#333333">
		<!-- CSS for click to reveal section -->
		<style>
			span.db{color:#59d8a1;font-weight:bold;font-family:atlas}
			span.dw{color:#ff7c66;font-weight:bold;font-family:atlas}
			span.title{color:#f4f4f4;font-weight:bold;font-size:70px;text-align:center}
			div.row {display: flex;}
			div.col {flex: 1; padding: 1em;}
		</style>
	</head>
  <body class='reveal-viewport'>
		<!-- Page Header -->
		<header role="banner" style='background-image:url(../assets/generic/Header.PNG);width:100%'>
      <nav role="navigation" style='align:left'>
        <ul>
					<li class="applied">
            <a href="https://platform.multiverse.io" title="Applied" target='_blank'>
							<p style='font-family:atlas'><strong>MultiVerse</strong></p>
            </a>
          </li>
          <li class="contents">
            <a href='#/1' title="Contents">
              <em>Contents</em>
            </a>
          </li> 
        </ul>
      </nav>
    </header>
 
		<div class="reveal" style='font-family:atlas;font-size:25px;color:#242456'>
			<div class="slides">
				<!-- Slide 1 -->
				<section data-background-image="../assets/generic/title_slide_alt.PNG">


					<div class="wrap aligncenter">
						<span class='title'> Advanced Techniques: Session 1 </span>        
					</div>
					<!-- Slide 1 Notes-->
					<aside class='notes'>
						Welcome apprentices to the session and select a warmup from <a href='https://docs.google.com/presentation/d/1jrSQya9EVyTf0t5e1FTP0g-jJOz6Lzw0g7xjJoixojk/edit?usp=sharing'> here</a>.
					</aside>
				</section>
				<!-- Slide 2 -->
				<section class='present' data-background-image="../assets/generic/info_yellow.PNG">
					<div class="wrap size-60 bg-white">           
						<h1> Session Outline </h1>
						<ul style='list-style-type:none;font-size:15px'>
							<li><a href='#/3'>  Data Warehouse </a></li>
							<li><a href='#/11'> Data Integration </a> </li>
							<li><a href='#/16'> Types of Data Integration </a> </li>
							<li><a href='#/18'> Data Integration Life Cycle </a> </li>
							<li><a href='#/20'> Data Profiling </a> </li>
							<li><a href='#/24'> Data Integration Techniques </a> </li>
							<li><a href='#/31'> Rules and Policies </a> </li>
							<li><a href='#/35'> ETL </a> </li>
							<li><a href='#/44'> Security </a> </li>
							<li><a href='#/46'> Automating the Process </a> </li>
							<li><a href='#/48'> Licenses vs Coding </a></li>
							<li><a href='#/52'> Master Data Management </a> </li>
							<li><a href='#/56'> Testing Strategies </a> </li>
							<li><a href='#/65'> Recap </a> </li>
						</ul>
					</div>
					<!-- Slide 2 Notes -->
					<aside class='notes'>
						Run through the plan of the day, plan to have a break about half way through
					</aside>
				</section>
				<!-- Slide 3 -->
				<section data-background-image="../assets/generic/info_yellow.PNG">
					<div class="wrap size-60 bg-white" style='width:max-content'>
						<h1> Learning Objectives </h1>
						<ul style='display:inline-block;text-align:left'>
							<li> <b>Understand</b> concepts of Data Integration and ETL techniques </li>
							<li> <b> Explain </b> the difference between <b> Data Integration</b> and <b> Data Migration</b></li>
							<li> <b> Explore </b> different testing strategies for Data Integration</li>
						</ul>          
					</div>
					<!-- Slide 3 Notes -->
					<aside class='notes'>
						Run through learning objectives, again explain that the purpose is for apprentices to be able to justify their reasons for using or not using the tools they have available.
					</aside>
				</section>
				<!-- Slide 4 -->
				<section data-background-image="../assets/generic/section.PNG">
					<div class="wrap aligncenter">
						<span class='title'> Data Warehouse</span>          
					</div>
					<!-- Slide 4 Notes -->
					<aside class='notes'>
						In today's session we will be considering why companies store data in data warehouses and how they go about doing it. Does anyone know what a data warehouse is?
					</aside>
				</section>
				<!-- Slide 5 -->
				<section data-background-image="assets/session_1/warehouse.PNG">				
					<div class='row r-hstack'>
						<div class='col'></div>
						<div class="col fade in" style='text-align:center;right:0px'>
							<span style ='color:#64abff;font-size:35px;width:max-content'> 'Data Warehousing' is a practice in <u>data management</u> whereby data is <u>copied from various operational systems</u> into a <u>persistant data store</u> in a <u>consistent format</u> to be used for <u>analysis, decision making and reporting</u>. 
							</span>	
						</div>
					</div>
					<!-- Slide 5 Notes -->
					<aside class='notes'>
						Read the quote. Essentially enterprises use warehouses to hold the vast amount of data they control in one location allowing for easier access for making data driven business decisions. Point out that for analysis you will need to hold both historical and current data (historical for training and testing, current to  actually make the analysis). 
					</aside>
				</section>
				<!-- Slide 6 -->
				<section data-background-image="../assets/generic/box_serious.PNG">
					<div class="wrap aligncenter" style='width:max-content'>
						<h2 style='color:#64abff'> Online Transactional Processing (OLTP)</h2>
						<p class='info' style='color:#242456'> OLTP provides transaction orientated applications, administering day to day transcations of an organisation. For example:</p>
						<p class='info fragment fade in' style='color:#242456'> Supermarkets </p>
						<p class='info fragment fade in' style='color:#242456'> Online banking </p>
						<p class='info fragment fade in' style='color:#242456'> Airline ticket booking </p>
						<p class='info fragment fade in' style='color:#242456'> Adding items to a shopping cart </p>
					</div>
					<!-- Slide 6 Notes -->
					<aside class='notes'>
						A couple of definitions (reminders from Module 2). OLTP is for processing day to day data such as transactions. This is often fast flowing data and better suited to a database such as a RDBMS which is highly structured.
					</aside>
				</section>
				<!-- Slide 7 -->
				<section data-background-image="../assets/generic/box_serious.PNG">
					<div class="wrap aligncenter" style='width:max-content'>
						<h2 style='color:#64abff'> Online Analytical Processing (OLAP)</h2>
						<p style='color:#242456'> OLAP consists of data analytics tools that are used for making business decisions. It provides an environment to leverage insights from multiple database systems at one time. For example:</p>
						<p class='fragment fade in' style='color:#242456'> Recommendation algorithms (e.g. Spotify suggested, Amazon products) </p>
						<p class='fragment fade in' style='color:#242456'> Virtual assisstants (e.g. Alexa, Siri)  </p>
						<p class='fragment fade in' style='color:#242456'> Targeted Adverts </p>
						<p class='fragment fade in' style='color:#242456'> Suggested LinekedIn connections </p>
					</div>
					<!-- Slide 7 Notes -->
					<aside class='notes'>
						OLAP allows for analytical decisions to be made from pulling together data from a variety of disparate sources. These are better suited to Data Warehouses which hold vast quantities of data in a variety of structures allowing for cross-referencing and powerful analytics. 
					</aside>
				</section>
				<!-- Slide 8 -->
				<section data-background-image='../assets/generic/main.PNG'>
					<img src='assets/session_1/star_schema.PNG'>
					<!-- Slide 8 Notes -->
					<aside class='notes'>
						An example of what a data warehouse might look like. In the center is the fact table which holds all the measurements (e.g. price of products, quantity sold, etc) aggregated in various ways. Surrounding it are the dimension tables which provide the basis for aggregating the measurements in the fact table. This format allows you to intuitively understand much of the information around a piece of data, for example, for a given number of order dollars you will be able to find out what products were sold, to what customers and by what salesperson on a certain day.
					</aside>
				</section>
				<section>
					<!-- Slide 9a -->
					<section data-background-image="../assets/generic/fun_box.PNG">
						<div class="wrap aligncenter">
							<span style ='color:black;font-size:70px;font-weight:bold;text-align:center'> <p class='fragment fade in' style='color:#ff7c66'> Data Warehouse</p> <p class='fragment fade in'>vs</p> <p class='fragment fade in' style='color:#59d8a1'>Database </p></span>
						</div>
						<!-- Slide 9a Notes -->
						<aside class='notes'>
							For apprentices benefit it will be worth exploring the differences between a data warehouse and a database (which we looked at in module 2). The key things to point out are when it is best to use each one. Press down to go through each difference individually. 
						</aside>
					</section>
					<!-- Slide 9b -->
					<section data-background-image="../assets/generic/circle_remix.PNG">	
						<h1><span class='dw'> Data Warehouse</span> vs <span class='db'>Database</span></h1>
						<h2> Type of Processing </h2>
						<div class='row r-hstack'>
							<div class='col fragment'>
								<p style='color:#ff7d67;font-size:35px'>OLAP</p>
							</div>
							<div class='col fragment'>
								<p style='color:#59d8a1;font-size:35px'>OLTP</p>
							</div>						
						</div>
						<!-- Slide 9b Notes -->
						<aside class='notes'>
							Databases (such as a RDBMS) are highly structured and normalised which means they are well suited to the fast flowing transactional data with the ability to cross reference tables using primary and foreign keys. They therefore use an OLTP system. As data warehouses hold all the available data in one source, it gives the potential for powerful analysis to be carried out quickly which is why it uses OLAP.
						</aside>
					</section>
					<!-- Slide 9c -->
					<section data-background-image="../assets/generic/circle_remix.PNG">					
						<h1><span class='dw'> Data Warehouse</span> vs <span class='db'>Database</span></h1>
						<h2> Data Structure </h2>
						<div class='row r-hstack'>
							<div class='col fragment'>
								<p style='color:#ff7d67;font-size:35px'>Denormalised table containing repeated data</p>
							</div>
							<div class='col fragment'>
								<p style='color:#59d8a1;font-size:35px'>Highly normalised with different tables</p>
							</div>						
						</div>	
						<!-- Slide 9c Notes -->
						<aside class='notes'>
							Databases have normalised tables which each contain different information (e.g. reference or transaction). Data warehouses follow a denormalised structure (often Star Schema) where a large central 'fact' table holds measurements (e.g. price and quantity of products) which may be aggregated in various ways. The fact table is surrounded by several 'dimension' tables which tells the fact table how to aggregate the data (e.g. by customer, salesperson, order date, etc). Typically data warehouses only hold structured data (unstructured data goes in a data lake, which is similar to a warehouse but for unstrctured data).
						</aside>
					</section>
					<!-- Slide 9d -->
					<section data-background-image="../assets/generic/circle_remix.PNG">
						<h1><span class='dw'> Data Warehouse</span> vs <span class='db'>Database</span></h1>
						<h2> Optimised For </h2>
						<div class='row r-hstack'>
							<div class='col fragment'>
								<p style='color:#ff7d67;font-size:35px'>Rapid execution of queries on large complex datasets</p>
							</div>
							<div class='col fragment'>
								<p style='color:#59d8a1;font-size:35px'>Updating, deleting and modifying data</p>
							</div>						
						</div>		
						<!-- Slide 9d Notes -->
						<aside class='notes'>
							As databases work with highly normalised tables, it is easy to update or modify the tables as you are only ever going to be editing one table at a time. Data warehouses are more complex and updating will take longer as you will need to consider both fact and dimension tables together. Data warehouses on the other hand are very well suited for rapid execution of queries on large complex datasets as all the data is held in one location.
						</aside>
					</section>
					<!-- Slide 9e -->
					<section data-background-image="../assets/generic/circle_remix.PNG">
						<h1><span class='dw'> Data Warehouse</span> vs <span class='db'>Database</span></h1>
						<h2> Data Timeline </h2>
						<div class='row r-hstack'>
							<div class='col fragment'>
								<p style='color:#ff7d67;font-size:35px'>Historical Data</p>
							</div>
							<div class='col fragment'>
								<p style='color:#59d8a1;font-size:35px'>Current real-time data</p>
							</div>						
						</div>
						<!-- Slide 9e Notes -->
						<aside class='notes'>
							As databases can be updated quickly and easily they will often hold current data (and can be updated in real time). Data warehouses are more complex and due to the way data is integrated will always be at least a little out of date.
						</aside>
					</section>
					<!-- Slide 9f -->
					<section data-background-image="../assets/generic/circle_remix.PNG">
						<h1><span class='dw'> Data Warehouse</span> vs <span class='db'>Database</span></h1>
						<h2> Uptime </h2>
						<div class='row r-hstack'>
							<div class='col fragment'>
								<p style='color:#ff7d67;font-size:35px'>Regular downtime to allow batch upload</p>
							</div>
							<div class='col fragment'>
								<p style='color:#59d8a1;font-size:35px'>Approx 100%</p>
							</div>						
						</div>
						<!-- Slide 9f Notes -->
						<aside class='notes'>
							The consequence of this is that if you want to update a data warehouse you will need to take it down temporarily. It is often a good idea to upload in batches over night when people will not likely need ot use it. As databases are agile and can be updated instantly, they will typically be online 100% of the time (except for maintenance)
						</aside>
					</section>
					<!-- Slide 9g -->
					<section data-background-image="../assets/generic/circle_remix.PNG">
						<h1><span class='dw'> Data Warehouse</span> vs <span class='db'>Database</span></h1>
						<h2> Query Type </h2>
						<div class='row r-hstack'>
							<div class='col fragment'>
								<p style='color:#ff7d67;font-size:35px'>Complex queries for in depth analysis</p>
							</div>
							<div class='col fragment'>
								<p style='color:#59d8a1;font-size:35px'>Simple transactional queries</p>
							</div>						
						</div>	
						<!-- Slide 9g Notes -->
						<aside class='notes'>
							Databases are suited for transactional data with quick references to certain aspects (e.g. product type, store information, etc). Data warehouses contain all relevant historical data aggregated as defined by the schema. This allows for complex queries that give in depth analysis that will help businesses make effective data driven decisions. 
						</aside>
					</section>
				</section>
				<!-- Slide 10 -->
				<section data-background-image="../assets/generic/table_back.PNG">
					<h1> Data Warehouse vs Database</h1>
					<table style='font-size:15px'>
						<tr>
							<th> &nbsp;</th>						
							<th> Data Warehouse </th>
							<th> Database </th>
						</tr>
						<tr>
							<td><b>Processing</b></td>
							<td> OLAP </td>
							<td> OLTP</td>
						</tr>
						<tr>
							<td><b>Structure</b></td>							
							<td> Denormalised table containing repeated data </td>
							<td> Highly normalised with different tables</td>
						</tr>
						<tr>
							<td><b>Optimisation</b></td>							
							<td> Rapidly executing low number of complex queries on large multi-dimensional datasets</td>
							<td> Updating, deleting and modifying data</td>
						</tr>
						<tr>
							<td><b>Timeline</b></td>							
							<td> Historical Data </td>
							<td> Current real-time data</td>
						</tr>
						<tr>
							<td><b>Uptime (SLA)</b></td>							
							<td> Regular downtime to allow batch uploads </td>
							<td> Appox 100% uptime</td>
						</tr>
						<tr>
							<td><b>Query Type</b></td>							
							<td> Complex Queries for in depth analysis </td>
							<td> Simple Transactional</td>
						</tr>
					</table>
					<!-- Slide 10 Notes -->
					<aside class='notes'>
						This table summarises all the information from the previous section, use this time to allow apprentices to ask questions.
					</aside>
				</section>
				<!-- Slide 11 -->
				<section data-background-image="assets/session_1/warehouse.PNG">
					<div class='row r-hstack' >
						<div class='col'>
						</div>
						<div class='col'>
						</div>
						<div class="col fade in" >
							<span style ='color:#242456;font-size:35px;font-weight:bold;text-align:center'> Data Warehouses are examples of Data Integration products</span>
						</div>
					</div>						          
					<!-- Slide 11 Notes -->
					<aside class='notes'>
						Much of today's session will be around data integration- how we combine data together for use in analysis. By the way data warehouses are set up, they are an example of how we perform data integration.
					</aside>
				</section>
				<!-- Slide 12 -->
				<section data-background-image="../assets/generic/section.PNG">
					<div class="wrap aligncenter">
						<span class='title'> Data Integration</span>          
					</div>
					<!-- Slide 12 Notes -->
					<aside class='notes'>
						So what is data integration? Ask if any of the apprentices have a definition for it already. 
					</aside>
				</section>
				<!-- Slide 13 -->
				<section data-background-image="../assets/generic/fun_box.PNG">
					<div class=' row r-hstack'>
						<div class='col'>
							<span style ='color:#4d61f4;font-size:60px;font-weight:bold;text-align:center'> Data Integration is the process of collecting data from a variety of sources into a single target. </span>
					</div>
						<div class='col'>
							<img src='assets/session_1/data_integration.PNG'>
						</div>
					</div>
					<!-- Slide 13 Notes -->
					<aside class='notes'>
						Read the quote. Data integration is simply the process of taking our data from our variety of disparate sources and combining them into one target (i.e. a data warehouse). 
					</aside>
				</section>
				<!-- Slide 14 -->
				<section data-background-image="../assets/generic/strike_force.PNG">
					<div class='row r-hstack'>
						<div class='col'>
							<h1 style='color:#f4f4f4'> Data Integration Sources </h1>
						</div>
						<div class='col fragment'>
							<p class='fragment' style='color:#242456;font-size:35px'> Text Files </p>
							<p class='fragment' style='color:#242456;font-size:35px'> Databases  </p>
							<p class='fragment' style='color:#242456;font-size:35px'> Spreadsheets </p>
							<p class='fragment' style='color:#242456;font-size:35px'> Applications </p>
						</div>
					</div>
					<!-- Slide 14 Notes -->
					<aside class='notes'>
						Ask the group to annotate the screen with their suggestions of what a source can be. Then show a few examples. A source is anything which holds data (typicaly structured in this case, but can be unstructured). Applications refers to software such as APIs which allow you to connect to databases.
					</aside>
				</section>
				<!-- Slide 15 -->
				<section data-background-image="../assets/generic/strike.PNG">
					<div class='row r-hstack'>
						<div class='col fragment'>
							<p class='fragment' style='color:#242456;font-size:35px'> Increased availability of data </p>
							<p class='fragment' style='color:#242456;font-size:35px'> Superior data integrity and quality  </p>
							<p class='fragment' style='color:#242456;font-size:35px'> Collaboration opportunities </p>
							<p class='fragment' style='color:#242456;font-size:35px'> Greater insights and improvements </p>
							<p class='fragment' style='color:#242456;font-size:35px'> Improved data consistency </p>
						</div>
						<div class='col'>
							<h1 style='color:#f4f4f4'> Benefits of Data Integration </h1>
						</div>
					</div>
					<!-- Slide 15 Notes -->
					<aside class='notes'>
						Ask the group to suggest the benefits of data integration. By integrating data from different sources into one location (warehouse) you are making your data more available to a wider range of people who need it which will allow for collaboration between different teams, more opportunities for insights and superior analysis. Additionally, with more eyes on the data you can be more confident of the integreity and quality. 
					</aside>
				</section>
				<!-- Slide 16 -->
				<section data-background-image='../assets/generic/fun_box.PNG'>
					<h1> Data Integration vs Data Migration </h1>
					<br>
					<p class='fragment'> Data Integration is the process of collecting data from a variety of sources into a unified view for analysis and making data driven business decisions.</p>
					<p class='fragment'> Data Migration is when the data is simply moved from one source to another. </p>
					<p class='fragment'> Companies will typically migrate data when implementing a new system or merging to a new environment.</p>
					<!-- Slide 16 Notes -->
					<aside class='notes'>
						Apprentices need to be aware (especially for their exam) that there is a difference between data migration and integration. Data integration is the process of combining data from different sources (some may be external to the organisation) to create a unified view which allows for analysis and business decisions. Migration is when the information already exists, it is just being moved from one location to another.
					</aside>
				</section>
				<!-- Slide 17 -->
				<section data-background-image="../assets/generic/section.PNG">
					<div class="wrap aligncenter">
						<span class='title'> Types of Data Integration</span>          
					</div>
					<!-- Slide 17 Notes -->
					<aside class='notes'>
						Now we know what data integration is and why we should do it, how should we do it? There are two methods, batch or real time. Let's consider both.
					</aside>
				</section>
				<!-- Slide 18 -->
				<section data-background-image="../assets/generic/circle_remix.PNG">
					<div class='row r-hstack'>
						<div class='col'>
							<h2 style='color:#ff7c66'><b> Batch Integration </b></h2>
							<br>
							<p class='fragment'> Data transfered from source to target in groups periodically </p>
							<p class='fragment'> Data formats and layouts must be consistent between source and target </p>
							<p class='fragment'> Source and target are <b>'asynchronus'</b> (source doesn't wait for target to process data) </p>
						</div>
						<br>
						<div class='col'>
							<h2 style='color:#59d8a1'><b> Real-time Integration </b></h2>
							<br>
							<p class='fragment'> Data transfered from source to target instantly </p>
							<p class='fragment'> Involved a much smaller amount of data and used when it is necessary to complete a single transaction </p>
							<p class='fragment'> Source and target are <b>'synchronus'</b> (changes in source are reflected in target) </p>
						</div>
					</div>
					<!-- Slide 18 Notes -->
					<aside class='notes'>
						Batch uploads is the common approach for data warehouses where data is moved from source to target in groups periodically. This means the source and target are asynchronus (not in sync) which allows for the source to be updated at any time, the target will follow suit later. It is advised however that batch uploads happen outside working hours to avoid disruption to people trying to use the target file. Real time integration sees data moved from source to target as it is created. If the source updates, so does the target. This is optimal only for small amounts of data due to the processing time needed (think how slow and unresponsive a dashboard would be if it was integrating constantly terabytes worth of data). 
					</aside>
				</section>
				<!-- Slide 19 -->
				<section data-background-image="../assets/generic/section.PNG">
					<div class="wrap aligncenter">
						<span class='title'> Data Integration Life Cycle</span>          
					</div>
					<!-- Slide 19 Notes -->
					<aside class='notes'>
						Now we will consider the process that you would follow if you were going to perform data integration from start to finish.
					</aside>
				</section>
				<!-- Slide 20a -->
				<section style='font-size:35px;width:100%'>
					<section data-background-image="../assets/generic/strike_force.PNG" style='width:100%'>
						<div class='row'>
							<div class='col'>
								<p style='color:#ff7c66'> 1. Scoping </p>
								<p style='color:#f4f4f4'> 2. Profiling </p>
								<p style='color:#f4f4f4'> 3. Design </p>
								<p style='color:#f4f4f4'> 4. Testing </p>
								<p style='color:#f4f4f4'> 5. Implementation </p>
							</div>
							<div class='col'>
								<p> Technical Requirements </p>
								<p> Business Requirements </p>
								<p> Data Requirements </p>
								<p> Operational Requirements </p>
							</div>
						</div>
						<!-- Slide 20a Notes -->
						<aside class='notes'>
							Introduce the five stages. In the first stage you will need to scope out the requirements for the integration- what technology do you need? Who will need access to the integrated target? What business questions will this integrated target be able to answer? What data/sources will be connected and do they need any work (i.e. cleaning)? This requirements elicitation is a necessary step as it will give you focus onto what you need to do as well as potentially mitigate and avoid costly errors later.  
						</aside>
					</section>
					<!-- Slide 20b -->
					<section data-background-image="../assets/generic/strike_force.PNG">
						<div class='row'>
							<div class='col'>
								<p style='color:#f4f4f4'> 1. Scoping </p>
								<p style='color:#ff7c66'> 2. Profiling </p>
								<p style='color:#f4f4f4'> 3. Design </p>
								<p style='color:#f4f4f4'> 4. Testing </p>
								<p style='color:#f4f4f4'> 5. Implementation </p>
							</div>
							<div class='col'>
								<p> Understand our data </p>
								<ul style='display:inline-block;text-align:left'>
									<li> Duplicates </li>
									<li> Null values</li>
									<li> Format </li>
									<li> Data Types </li>
									<li> Values </li>
								</ul>
							</div>
						</div>
						<!-- Slide 20b Notes -->
						<aside class='notes'>
							Next comes profiling. You have already scoped out the data sources you are going to use, but are they in a useable format? You will need to check and clean the data (potentially writing scripts to automate this process) to ensure the sources will be in a consistent format with the target. You will also need to check if duplicates or nulls will be created as a result of the integration and mitigate for them. 
						</aside>
					</section>
					<!-- Slide 20c -->
					<section data-background-image="../assets/generic/strike_force.PNG">
						<div class='row'>
							<div class='col'>
								<p style='color:#f4f4f4'> 1. Scoping </p>
								<p style='color:#f4f4f4'> 2. Profiling </p>
								<p style='color:#ff7c66'> 3. Design </p>
								<p style='color:#f4f4f4'> 4. Testing </p>
								<p style='color:#f4f4f4'> 5. Implementation </p>
							</div>
							<div class='col'>
								<p> Decide on the architecture of the data warehouse using business, technical and operational metdata </p>
							</div>
						</div>
						<!-- Slide 20c Notes -->
						<aside class='notes'>
							Now you have your sources identified and ready, you will need to decide on the structure of the data warehouse. The most common approach is the star schema, where measurements will be held in a central fact table in various aggregations as defined by the surrounding dimension tables. Based on the business need and technical opportunities you have available you will need to decide what is stored within the fact table and what dimensions you would like/need to include. 
						</aside>
					</section>
					<!-- Slide 20d -->
					<section data-background-image="../assets/generic/strike_force.PNG">
						<div class='row'>
							<div class='col'>
								<p style='color:#f4f4f4'> 1. Scoping </p>
								<p style='color:#f4f4f4'> 2. Profiling </p>
								<p style='color:#f4f4f4'> 3. Design </p>
								<p style='color:#ff7c66'> 4. Testing </p>
								<p style='color:#f4f4f4'> 5. Implementation </p>
							</div>
							<div class='col'>
								<p> Validation and verification of coding interface </p>
								<p> Test the process works </p>
								
								<p> User Acceptance Testing (UAT) </p>
								<p> Technical Acceptance Testing (TAT) </p>
								<p> Performance Stress Testing (PST)</p>
								
							</div>
						</div>
						<!-- Slide 20d Notes -->
						<aside class='notes'>
							Once you have the database designed and the sources identified and made ready it is time to test that it all works. You will need to validate the process (is the correct data being pulled? Is it joining on the columns I had set?) and verify the output (does it look like how you expected? Is it doing what you want it to?). There are various testing strategies available which we will look into later. If there are any failures, you will need to document them and then fix them. This should all be tested at a local level.
						</aside>
					</section>
					<!-- Slide 20ae -->
					<section data-background-image="../assets/generic/strike_force.PNG">
						<div class='row'>
							<div class='col'>
								<p style='color:#f4f4f4'> 1. Scoping </p>
								<p style='color:#f4f4f4'> 2. Profiling </p>
								<p style='color:#f4f4f4'> 3. Design </p>
								<p style='color:#f4f4f4'> 4. Testing </p>
								<p style='color:#ff7c66'> 5. Implementation </p>
							</div>
							<div class='col'>
								<p> Implement the process at an operational level </p>
							</div>
						</div>
						<!-- Slide 20e Notes -->
						<aside class='notes'>
							Finally, if you are confident that everything works as intended then it is time to implement the process! This may involve training up colleagues or at least amking them aware the data warehouse exists. You should also schedule regular maintenance as well as a batch upload schedule (ideally out of work hours) that will allow the integration process to be updated.
						</aside>
					</section>
				</section>
				<!-- Slide 21 -->
				<section data-background-image="../assets/generic/section.PNG">
					<div class="wrap aligncenter">
						<span class='title'> Data Profiling</span>          
					</div>
					<!-- Slide 21 Notes -->
					<aside class='notes'>
						As mentioned in the previous section, an important aspect of identifying data sources is profiling them to ensure they contain the data you want and in the correct form. We will now look into this in more detail.
					</aside>
				</section>
				<!-- Slide 22 -->
				<section data-background-image="../assets/generic/fun_box.PNG">
					<div class=' row r-hstack'>
						<div class='col'>
							<span style ='color:#4d61f4;font-size:50px;font-weight:bold;text-align:center'> Data Profliling is the process of reviewing and analysing data to be used in an extract to understand the format and content. </span>
					</div>
						<div class='col'>
							<img src='assets/session_1/data_profile.PNG'>
						</div>
					</div>
					<!-- Slide 22 Notes -->
					<aside class='notes'>
						The purpose is to assess data quality as well as risks involved in integrating data in new applications. It also allows you to have an overall view of the data for data management and governance. Ask apprentices if they have any experience of profiling, or what they might expect it to involve. 
					</aside>
				</section>
				<!-- Slide 23a -->
				<section>
					<section data-background-image="../assets/generic/main.PNG">
						<h1 style='color:#64abff'> Uses of Data Profiling </h2>
						<br>
						<p class='fragment'> Develop metadata and documentation </p>
						<p class='fragment'> Report data formats, uniqueness, consistency, correctness and null values </p>
						<p class='fragment'> Compare field names across data stores/tables </p>
						<p class='fragment'> Can be difficult to arrange if it innvolves personal or sensitive information </p>
						<!-- Slide 23a Notes -->
						<aside class='notes'>
							Something to be aware of: this can sometimes be difficult to arrange if it involves sensitive or personal information- you cannot publish PII in any form, even when describing the data. Ask the apprentices what sort of information they think it would be important to include. Go down for an example of a data profile.
						</aside>
					</section>
					<!-- Slide 23b -->
					<section data-background-image="../assets/generic/table_back.PNG">
						<table style='text-align:center'>
							<tr>
								<th> Dataset Name </th>
								<th> Format </th>
								<th> Dataset Type </th>
							</tr>
							<tr>
								<td> My_dataset </td>
								<td> RDBMS </td>
								<td> Reference </td>
							</tr>
						</table>
						<p> Author: Multiverse; Last editied: 01/03/2021 </p>
						<div class='wrap' style='width:100%;text-align:center'>
							<table style='width:max-content;font-size:15px;text-align:center;margin-left:auto;margin-right:auto'>
								<tr>
									<th> Field Name </th>
									<th> Data Type </th>
									<th> Count </th>
									<th> Null Values </th>
									<th> % Nulls </th>
									<th> Maximum Value </th>
									<th> Minimum Value </th>
								</tr>
								<tr>
									<td> customer_surname </td>
									<td> string </td>
									<td> 1501 </td>
									<td> 0 </td>
									<td> 0% </td>
									<td> zabini </td>
									<td> abbots </td>
								</tr>
							</table>
						</div>
						<!-- Slide 23b Notes -->
						<aside class='notes'>
							You will likely want a table which describes the dataset itself, including what format it is and who the author is. What other information might you want to include? The rest of the profile will be about the fields in the data, what data types they are, how many null values, etc. This information will help give you a clear idea what the data source involves and how you will want to incorporate it during the integration.
					</section>
				</section>
				<!-- Slide 24 -->
				<section data-background-image="../assets/generic/tweenies.PNG">
					<div class='row r-hstack'>
						<div class='col'></div>
						<div class="col wrap aligncenter" style='width:max-content'>
							<h2 style = color:#1d98ff><b> Activity </b></h2>
							<br>
							<ul style='display:inline-block;text-align:left'>
								<li> Open the products Jupyter Notebook</li>
								<li> Using pandas, profile the data for: 
									<ul style='display:inline-block;text-align:left'>
										<li> Data Format </li>
										<li> Field Names </li>
										<li> Field Data Types </li>
										<li> Summary Statistics of the data </li>
										<li> Information on Null values </li>
										<li> Any other information you think is necessary </li>
									</ul>
								<li> Create a text document to show this information </li>
							</ul>
						</div>
					</div>
					<!-- Slide 24 Notes -->
					<aside class='notes'>
						Now it is your turn. This exercise will take you back to the products table we used back in the SQL bootcamp. In groups (one persion share screen) create a data profile for this dataset. Give 10-15 minutes for this + time for presentations.
					</aside>
				</section>
				<!-- Slide 25 -->
				<section data-background-image="../assets/generic/section.PNG">
					<div class="wrap aligncenter">
						<span class='title'> Data Integration Techniques</span>          
					</div>
					<!-- Slide 25 Notes -->
					<aside class='notes'>
						So how do you go about integrating data? 
					</aside>
				</section>
				<!-- Slide 26 -->
				<section data-background-image="../assets/generic/strike_force.PNG">
					<div class='row r-hstack'>
						<div class='col'>
							<h2 style='color:#f4f4f4'> Data Integration Techniques </h2>
						</div>
						<div class='col'>
							<p> Manual Data Integration </p>
							<p> Middleware Data Integration </p>
							<p> Application Based Integration </p>
							<p> Uniform Access Integration </p>
							<p> Common Storage Integration </p>
						</div>
					</div>
					<!-- Slide 26 Notes -->
					<aside class='notes'>
						For this session we will consider the following five techniques. 
					</aside>
				</section>
				<section>
					<!-- Slide 27a -->
					<section data-background-image="../assets/generic/circle_remix.PNG">
						<div class="wrap" style='width:max-content'>
							<h2> Manual Data Integration </h2>
							<br>
							<p> Whole process (e.g. data collection and cleaning, connecting sources) done manually by a human </p>
							<p> Best for one-time instances </p>
						</div>
						<!-- Slide 27a Notes -->
					<aside class='notes'>
						Manual data integration does exactly as it sounds, a human manually performs the whole process (visually inspecting the data, cleaning it and joining the sources). This takes time and opens up the possibility of human error, so it best used for small and quick updates.
					</aside>
					</section>
					<!-- Slide 27b -->
					<section data-background-image="../assets/generic/circle_remix.PNG">
						<h2> Manual Data Integration </h2>
						<div class='row'>
							<div class='col'> 
								<h3 style='color:#ff7c66'> Benefits </h3>
								<br>
								<p> Reduced Costs </p>
								<p> Greater Freedom </p>
							</div>
							<div class='col'> 
								<h3 style='color:#59d8a1'> Drawbacks </h3>
								<br>
								<p> Difficulty Scaling </p>
								<p> Greater Room for Error </p>
								<p> Less Access </p> 
							</div>
						</div>
						<!-- Slide 27b Notes -->
						<aside class='notes'>
							Integrating data manually will be cheaper than using specialised software but it is not an appropriate technique for larger volumes of data, or when it is fast flowing. It will take the user too long to be efficient. Another drawback is that only the one person will have access, which can cause problems if they are not available when the integration needs to happen.
						</aside>
					</section>
				</section>
				<section>
					<!-- Slide 28a -->
					<section data-background-image="../assets/generic/circle_remix.PNG">						
						<h2> Middleware Data Integration </h2>
						<br>
						<p> Using softwares that connect applicatons and transfers between them and databases (no coding) </p>
						<p> Acts an interpreter between systems and enacts an automatic transfer </p>
						<p> Examples include Microsoft Dynamic CRM, SAP and Sage </p>
						<!-- Slide 28a Notes -->
						<aside class='notes'>
							Middleware softwares act like a 'middle man' between your various sources and the target. This method requires no coding and allows for automation of the process. Within the software you will need to state the connections and relationships and it will do the rest.
						</aside>
					</section>
					<!-- Slide 28b -->
					<section data-background-image="../assets/generic/circle_remix.PNG">
						<h2> Middleware Data Integration </h2>
						<div class='row'>
							<div class='col'> 
								<h3 style='color:#ff7c66'> Benefits </h3>
								<br>
								<p> Fast and Efficient </p>
								<p> Scalable </p>
								<p> Time Saving </p> 
							</div>
							<div class='col'>
								<h3 style='color:#59d8a1'> Drawbacks </h3>
								<br>
								<p> Less Access </p>
								<p> Limited Functionality </p>
							</div>
						</div>
						<!-- Slide 28b Notes -->
						<aside class='notes'>
							While this method is fast, efficient and scalable you are outsourcing the work which reduces your access to the process and limits you to whatever the software allows.
						</aside>
					</section>
				</section>
				<section>
					<!-- Slide 29a -->
					<section data-background-image="../assets/generic/circle_remix.PNG">						
						<h2> Application Based Integration </h2>
						<br>
						<p> Specialised softwares that locate, retrieve and integrate data </p>
						<p> Mostly suited to integrate limited amounts of data and sources </p>
						<!-- Slide 29a Notes -->
						<aside class='notes'>
							Taking it a step further, you have application based integtation which essentially does the whole integration process. This is only suited to smaller amounts of data and sources however. This is due to the increased complexity of adding more data and sources (more room for error) which would result in you spending most of your time troubleshooting (and might as well do it yourself).
						</aside>
					</section>
					<!-- Slide 29b -->
					<section data-background-image="../assets/generic/circle_remix.PNG">
						<h2> Application Based Integration </h2>
						<div class='row'>
							<div class='col'> 
								<h3 style='color:#ff7c66'> Benefits </h3>
								<br>
								<p> Simplified Process </p>
								<p> Wide Range of Compatibility </p>
								<p> Fewer Resources Used </p> 
							</div>
							<div class='col'> 
								<h3 style='color:#59d8a1'> Drawbacks </h3>
								<br>
								<p> Complicated Setup </p>
								<p> Limited Access </p>
								<p> Difficult Data Management </p> 
							</div>
						</div>
						<!-- Slide 29b Notes -->
						<aside class='notes'>
							While the process is simple and allows for an organisation to devote fewer resources for the process, it does mean that you are reducing access and control to your own data. If you need to change the structure, or want to incorporate new data this process can be difficult as you will need to set up everything up again.
						</aside>
					</section>
				</section>
				<section>
					<!-- Slide 30a -->
					<section data-background-image="../assets/generic/circle_remix.PNG">
						<h2> Uniform Access Integration </h2>
						<br>
						<p> Also known as "Virtual Integration" </p>
						<p> Data is allowed to stay in its original location when being accessed  </p>
						<p> Provides a unified view quickly to both customers and across platforms </p>
						<!-- Slide 30a Notes -->
						<aside class='notes'>
							This process inetgrates disparate sources together in such a way that all users have the same unified view. Each user will have direct access to the data locally and when they make an edit to a source the change will be reflected for all others instantly.
						</aside>
					</section>
					<!-- Slide 30b -->
					<section data-background-image="../assets/generic/circle_remix.PNG">
						<h2> Uniform Access Integration </h2>
						<div class='row'>
							<div class='col'> 
								<h3 style='color:#ff7c66'> Benefits </h3>
								<br>
								<p> Simplified View of Data </p>
								<p> Easy Access </p>
								<p> Lower Storage Requirements </p> 
							</div>
							<div class='col'> 
								<h3 style='color:#59d8a1'> Drawbacks </h3>
								<br>
								<p> Data Management can be Difficult </p>
								<p> Data Integrity could be Compromised </p> 
							</div>
						</div>
						<!-- Slide 30b Notes -->
						<aside class='notes'>
							This method allows for easy access for a lot of users and provides a simple unified view of the data. However, if that many people have access (and editing rights) it means managing the data and keeping it clean can be difficult. 
						</aside>
					</section>
				</section>
				<section>
					<!-- Slide 31a -->
					<section data-background-image="../assets/generic/circle_remix.PNG">						
						<h2> Common Storage Integration <br> (Data Warehouse)</h2>
						<br>
						<p> Similar to uniform access except it creates and stores a copy of the data </p>
						<p> One of the most popular integration methods </p>
						<!-- Slide 31a Notes -->
						<aside class='notes'>
							The most common method is to use a data warehouse. Instead of everyone having access to the unified view directly, a copy is made, so that if one person makes an edit to their source it will not be reflected until the copy is updated.
						</aside>
					</section>
					<!-- Slide 31b -->
					<section data-background-image="../assets/generic/circle_remix.PNG">
						<h2> Common Storage Integration <br> (Data Warehouse)</h2>
						<div class='row'>
							<div class='col'> 
								<h3 style='color:#ff7c66'> Benefits </h3>
								<br>
								<p> Reduced Burden </p>
								<p> Cleaner Data Appearance </p>
								<p> Enhanced Data Analytics </p> 
							</div>
							<div class='col'> 
								<h3 style='color:#59d8a1'> Drawbacks </h3>
								<br>
								<p> Increased Storage Costs </p>
								<p> Higher Maintenance Costs </p> 
							</div>
						</div>
						<!-- Slide 31b Notes -->
						<aside class='notes'>
							The advantage of this is that data integrity can be maintained (and controlled) allowing for enhanced data analytics as users can trust the data is in a useable form. However, this does mean the unfied file has to be stored somewhere (and maintained) which carries more costs than hosting the sources locally.
						</aside>
					</section>
				</section>
				<!-- Slide 32 -->
				<section data-background-image="../assets/generic/section.PNG">
					<div class="wrap aligncenter">
						<span class='title'> Rules and Policies</span>          
					</div>
					<!-- Slide 32 Notes -->
					<aside class='notes'>
						Data integration potentially carries a range of risks around security and GDPR. In this section we will discuss how we can mitigate for these. Ask the group: what do  you think the greatest security risks are with data integration?
					</aside>
				</section>
				<!-- Slide 33 -->
				<section data-background-image="../assets/generic/table_back.PNG">
					<div style='font-size:35px'>
						<p> You must specifiy security policies (e.g. who has access?) </p>
						<p> Data integrated should be immutable (unchanging) </p>
						<p> Validation checks should be carried out during the process </p>
						<ul style='display:inline-block;text-align:left'>
							<br>
							<li> Validate the source and target table structure and data types </li>
							<br>
							<li> Validate the column names against a mapping document </li>
						</ul>			
					</div>
					<!-- Slide 33 Notes -->
					<aside class='notes'>
						With data (particularly PII or insider data) the question has to be, does this person need access? GDPR states that data must be processed in a manner which secures its security and used in a way which is relevant. A way to ensure this is to only give access to those who need it, so having a set of security policies and rules (including how to get access approval and how they data should be used) should be established. To help protect data integrity, the data itself should not be changed once it has been integrated- it should be in the form exactly as you defined it. You should caary out validation checks throughout the process to ensure the source data is in the correct form, the column names are mapping correctly and other errors (such as incorrect data types, null values and outliers) are identified and dealt with. You should also check that there isn't a 'back door' that will allow users (potentially malicious) to gain access.
					</aside>
				</section>
				<!-- Slide 34 -->
				<section data-background-image="../assets/generic/table_back.PNG">
					<div style='font-size:35px'>
						<p> Verification is also carried out on the Data Warehouse </p>
						<br>
						<ul style='display:inline-block;text-align:left'>
							<li> Verify the data is accurate </li>
							<br>
							<li> Verify the data is correct </li>
							<br>
							<li> Verify the data has not been duplicated in the Data Warehouse </li>
					</ul>
					</div>
					<!-- Slide 34 Notes -->
					<aside class='notes'>
						You should also verify the data in the warehouse on a regular basis. Make sure it is accurate and up to data and being used exactly as specified (this is a part of GDPR compliance). If the data is no longer relevant it should be removed from the warehouse. 
					</aside>
				</section>
				<!-- Slide 35a -->	
				<section>
					<section data-background-image="../assets/generic/main.PNG">
						<div class='r-stack'>
							<h1 class='fragment fade-out' style='color:#4d61f4' data-fragment-index="0"> If you are wanting to use Business Data... </h1>
							<h1 class='fragment' style='color:#ff7c66' data-fragment-index="0"> Get Permission from the Data Owner! </h1>
						</div>
						<!-- Slide 35a Notes -->
						<aside class='notes'>
							Something else you will need to consider is if you do not own the data you are trying to integrate...
						</aside>
					</section>
					<!-- Slide 35b -->
					<section data-background-image="../assets/generic/main.PNG" >
						<div style='color:#242456'>
							<p> Data owners are given the right to decode who can have access to enterprise data.</p>
							<p> The process involved may be something like this:</p>
							<p class='fragment'> A person (staff member, contractor, supplier, etc) requests access to information </p>
							<p class='fragment'> A business resource (Data owner, manager) will review the request </p>
							<p class='fragment'> A techinical resources (usually a DBA) physically grants permission to an application, database or other data store containing the data. </p>
							<p class='fragment'> Often the permission follows a CRUD schema (create, read, update, delete)</p>
						</div>
						<!-- Slide 35b Notes -->
						<aside class='notes'>
							Like any intellectual property, the owner has the right who can have (and not have) access. This will need to be justified in a business context (if internal) and potentially have a contract drawn up (if external) to gain access. Normally the process to request access is as follows: you make the request, someone will review the request (potentially clarifying details), a database administrator (DBA) will grant access (if approved) and provide instructions on how you can retreive or connect the data. Access permission should be reviewed regularly, with permissions updated or removed as necessary.
						</aside>
					</section>
				</section>
				<!-- Slide 36 -->
				<section data-background-image="../assets/generic/section.PNG">
					<div class="wrap aligncenter">
						<span class='title'> ETL</span>          
					</div>
					<!-- Slide 36 Notes -->
					<aside class='notes'>
						Back in module 1 we briefly looked at a process called ETL. Does anyone remember what it stands for? This is a process commonly used with data integration.
					</aside>
				</section>
				<!-- Slide 37 -->
				<section data-background-image="../assets/generic/strike_force.PNG">
					<div class='row'>
						<div class='col'> 
							<h1 style='color:#f4f4f4'> E </h1>
							<h1 style='color:#f4f4f4'> T </h1>
							<h1 style='color:#f4f4f4'> L </h1>
						</div>
						<div class='col'>
							<h1 class='fragment' style='color:#4d61f4'> Extract </h1>
							<h1 class='fragment' style='color:#4d61f4'> Transform </h1>
							<h1 class='fragment' style='color:#4d61f4'> Load </h1>
						</div>
					</div>
					<!-- Slide 37 Notes -->
					<aside class='notes'>
						ETL stands for Extract, Transform, Load and we will review each step in the following slides. 
					</aside>
				</section>
				<!-- Slide 38 -->
				<section data-background-image="../assets/generic/fun_box.PNG">
					<div style='color:#4d61f4;font-size:35px'>
						<p> A process of <u>Data Integration</u> from <u>Multiple Sources</u></p>
						<p> It allows business the ability to gather data from multiple sources and consolidate into a single, centralised location </p>
						<p> This can be hard coded or using a licensed product </p>
					</div>
					<!-- Slide 38 Notes -->
					<aside class='notes'>
						ETL is the process businesses follow to integrate their data, you can gather data from a multitude of disparate sources into one unified view. As discussed earlier, this can be done manually or by using prebuilt software such as middleware, applications or data warehouses.
					</aside>
				</section>				
				<section>
					<!-- Slide 39a -->
					<section data-background-image="../assets/generic/strike.PNG">
						<div class='row'>
							<div class='col'>
								<p class='fragment'> Data is accessed from the source </p>
								<p class='fragment'> For this stage to be effective, a basic understanding of the data is required </p>
								<p class='fragment'> There are two methods: </p>
								<ul class='fragment' style='display:inline-block;text-align:left'>
									<li class='fragment'> Current system sends out a copy </li>
									<li class='fragment'> Other system comes in and grabs the data </li>
								</ul>
								<br>
								<br>
								<p class='fragment'> Commonly done with SQL queries if data is in databases </p>
							</div>
							<div class='col'>
								<h1 style='color:#f4f4f4'> Extract </h1>
							</div>
						</div>
						<!-- Slide 39a Notes -->
						<aside class='notes'>
							The first stage in the ETL process is to extract the data from the disparate sources. By this point the data profiling will have already been carried out, so the developer would know which columns are being extracted, what their datatypes and formats are as well as other summary statistics. There are two main methods, either the source sends out a copy of the data (keeping a local copy) or the system removes the data from the source directly (no local copy). This is often done using SQL queries.
						</aside>
					</section>
					<!-- Slide 39b -->
					<section data-background-image="../assets/generic/main.PNG">
						<h1> Extraction </h1>
						<br>
						<div class='row'>
							<div class='col'>
								<p> Can be hard-coded or tool-based </p>
								<p> For hard-coding in python: </p>
								<ul style='display:inline-block;text-align:left'>
									<li> CSV Reader (python or R)</li>
									<li> Pandas </li>
									<li> Luigi </li>
								</ul>
							</div>
							<div class='col'>
								<img src='assets/session_1/extract.PNG'>
							</div>
						</div>
						<br>
						<h3> Pandas is not just a data analysis library but can also be used for extraction </h3>
						<!-- Slide 39b Notes -->
						<aside class='notes'>
							You have already met a method of extraction- pandas! When you import a dataset into a pandas workspace you are extracting data (the whole ETL process can manually be done in Jupyter Notebook as you will see). 
						</aside>
					</section>
					<!-- Slide 39c -->
					<section data-background-image="../assets/generic/main.PNG">
						<h1> Extraction </h1>
						<br>
						<div class='row'>
							<div class='col'>
								<p> You can connect to a SQL server to extract data </p>
								<p> This can be done in python using:</p>
								<ul style='display:inline-block;text-align:left'>
									<li> Psycopg2 (for postgreSQL)</li>
									<li> SQLAlchemy</li>
									<li> SQLite3 </li>
								</ul>
							</div>
							<div class='col'>
								<img src='assets/session_1/extract_2.PNG'>
							</div>
						</div>
						<!-- Slide 39c Notes -->
						<aside class='notes'>
							We will see in a couple of minutes that it is possible to connect a SQL database directly to a python notebook using libraries such as psycopg2. This allows us to write SQL queries in python.
						</aside>
					</section>
				</section>
				<!-- Slide 40 -->
				<section data-background-image="../assets/generic/tweenies.PNG">
					<div class='row'>
						<div class='col'></div>
						<div class='col'>
							<h2 style = color:#1d98ff><b> Activity </b></h2>
							<br>
							<p> Open Jupyter Notebook ETL_python </p>
							<p> Complete Section 1: Extraction </p>
						</div>
					</div>
					<!-- Slide 40 Notes -->
					<aside class='notes'>
						Open the notebook and connect the postgres server to the python workbook, demonstrate how to write some queries and run them. Note, extracting the sales table might take a while so you may want to add the LIMIT 100 argument to your query. Then allow apprentices 10 minutes to extract the rest of the data and explore.
					</aside>
				</section>
				<section>
					<!-- Slide 41a-->
					<section data-background-image="../assets/generic/strike.PNG">
						<div class='row'>
							<div class='col'>
								<p class='fragment'> Transform the data to be compatible with the target data structure </p>
								<p class='fragment'> Sometimes simple, sometimes near on impossible </p>
								<p class='fragment'> Requires detailed requirements elicitation </p>
							</div>
							<div class='col'>
								<h1 style='display:none'>Extract</h1>
								<h1 style='color:#f4f4f4'> Transform </h1>
							</div>
						</div>
						<!-- Slide 41a Notes -->
						<aside class='notes'>
							Once you have extracted your data you will need to make sure all of it is compatible and in a useable form. This means applying transformations to the data which sometimes can be simple, but sometimes near on impossible (especially with unstructured data). This is why it is important to profile the data at source, verifying it is in a useable form. Ask the apprentices what transformations may be necessary.
						</aside>
					</section>
					<!-- Slide 41b -->
					<section data-background-image="../assets/generic/main.PNG">
						<p> Transformations could include:
						<ul class='fragment' style='display:inline-block;text-align:left'>
							<li class='fragment'> Mapping field from source to target </li>
							<li class='fragment'> String manipulation and manual data standardisation </li>
							<li class='fragment'> Aggregation and normalisation </li>
							<li class='fragment'> Calculations </li>
							<li class='fragment'> Dealing with duplicate values </li>
							<li class='fragment'> Data validation </li>
						</ul>
						<!-- Slide 41b Notes -->
						<aside class='notes'>
							Go through the list, ask if any others can be added.
						</aside>
					</section>
					<!-- Slide 41c -->
					<section data-background-image="../assets/generic/main.PNG">
						<h1> Transformation </h1>
						<div class='row'>
							<div class='col'>
								<p><b>Null Values</b></p>
								<img src='assets/session_1/null.PNG'>
							</div>
							<div class='col'>
								<p><b> Convert Datatypes</b></p>
								<img src='assets/session_1/convert.PNG'>
							</div>
						</div>
						<!-- Slide 41c Notes -->
						<aside class='notes'>
							We saw back in the EDA python session there is a wide array of funcitons available to transform data. Middleware and application software, as well as data warehouses will also have transformation tools to help with this process. Although, doing it yourself initially is often a worthwhile thing to do so you know what to expect.
						</aside>
					</section>
					<!-- Slide 41d -->
					<section data-background-image="../assets/generic/main.PNG">
						<h1> Transformation </h1>
						<div class='row'>
							<div class='col'>
								<p><b>Deduplication</b></p>
								<img src='assets/session_1/duplicate.PNG'>
							</div>
							<div class='col'>
								<p><b> Rename Fields</b></p>
								<img src='assets/session_1/rename.PNG'>
							</div>
						</div>
						<!-- Slide 41d Notes -->
						<aside class='notes'>
							Ask apprentices why duplicated data is a problem (increased storage costs, redundant information ,etc)
						</aside>
					</section>
				</section>
				<!-- Slide 42 -->
				<section data-background-image="../assets/generic/tweenies.PNG">
					<div class='row'>
						<div class='col'></div>
						<div class='col'>
							<h2 style = color:#1d98ff><b> Activity </b></h2>
							<br>
							<p> Open Jupyter Notebook ETL_python </p>
							<p> Complete Section 2: Transformation </p>
						</div>
					</div>
					<!-- Slide 42 Notes -->
					<aside class='notes'>
						Give apprentices 10-15 minutes to work through the transformation questions. Help apprentices appreciate that transforming data is the data cleaning stage and should not be rushed as any errors here could lead to expensive conequences down the line (incorrect analysis, failure to load, etc).
					</aside>
				</section>
				<section>
					<!-- Slide 43a -->
					<section data-background-image="../assets/generic/strike.PNG">
						<div class='row'>
							<div class='col'>
								<p class='fragment'> Load the data into the target data structure </p>
								<p class='fragment'> Either write code to insert data or make use of application code that already exists </p>
								<p class='fragment'> Examples include loading into a database or Data Warehouse </p>
								<p class='fragment'> Could involve joining all extracted data into a single table
							</div>
							<div class='col'>
								<h1 style='display:none'>Extract</h1>
								<h1 style='display:none'>Transform</h1>
								<h1 style='color:#f4f4f4'> Load </h1>
							</div>
						</div>
						<!-- Slide 43a Notes -->
						<aside class='notes'>
							The final step in the process is loading, combining these transformed sources into one unified view. The data structure of the target should have been pre definied and the data should join cleanly (if previous steps have been followed properly...). This could loading data into a warehouse, or just creating one table.
						</aside>
					</section>
					<!-- Slide 43b -->
					<section data-background-image="../assets/generic/main.PNG">
						<h1> Loading </h1>						
						<img src='assets/session_1/load_1.PNG'>
						<!-- Slide 43b Notes -->
						<aside class='notes'>
							Any join is an example of loading (including VLOOKUP) and joins in python or SQL.
						</aside>
					</section>
				</section>
				<!-- Slide 44 -->
				<section data-background-image="../assets/generic/tweenies.PNG">
					<div class='row'>
						<div class='col'></div>
						<div class='col'>
							<h2 style = color:#1d98ff><b> Activity </b></h2>
							<br>
							<p> Open Jupyter Notebook ETL_python </p>
							<p> Complete Section 3: Loading </p>
						</div>
					</div>
					<!-- Slide 44 Notes -->
					<aside class='notes'>
						Give 5 minutes for apprentices to load the data into one unified view. If they would like, they can explore doing this in BigQUery but there won't be time to do this in the session itself.
					</aside>
				</section>
				<!-- Slide 45 -->
				<section data-background-image="../assets/generic/section.PNG">
					<div class="wrap aligncenter">
						<span class='title'> Security</span>          
					</div>
					<!-- Slide 45 Notes -->
					<aside class='notes'>
						ETL is the process being data integration, and as discussed earlier needs to be done in a way which protects the data from being accessed by the wrong people.
					</aside>
				</section>
				<!-- Slide 46 -->
				<section data-background-image="../assets/generic/box_serious.PNG">
					<p> Some tips to help you run your ETL processes more securely: </p>
					<ul class='fragment' style='display:inline-block;text-align:left'>
						<li class='fragment'> Download the data onto a secure server </li>
						<li class='fragment'> Run ETL processes on local files or business/enterprise databases </li>
						<li class='fragment'> If the data owner has not given you the necessary permissions to write data to the target you will need to hand your script to the development team to implement </li>
					</ul>
					<!-- Slide 46 Notes -->
					<aside class='notes'>
						Normally scripts will run on business servers and not be connected to the internet (unless your data source is online). Therefore when doing ETL it should be done on your organisation's secure server (with a VPN on your computer). If your company doesn't have a server for this, there are secure commercial options such as AWS. 
					</aside>
				</section>
				<!-- Slide 47 -->
				<section data-background-image="../assets/generic/section.PNG">
					<div class="wrap aligncenter">
						<span class='title'> Automating the Process</span>          
					</div>
					<!-- Slide 47 Notes -->
					<aside class='notes'>
						Integrating data into a warehouse can be a long process (especially if done manually). If you are looking to do regular batch uploads, it is worth considering automation as a way to save time and costs.
					</aside>
				</section>
				<section>
					<!-- Slide 48a -->
					<section data-background-image="../assets/generic/fun_box.PNG">
						<p style ='color:#4d61f4;font-size:35px'> If your ETL process is unlikely to be a one off then it may be more efficient to automate the process. 	</p>	
						<p style ='color:#4d61f4;font-size:35px'> You will need to assess when new data becomes available to determine how often your scripts need to run.</p>
						<!-- Slide 48a Notes -->
						<aside class='notes'>
							Read the quote. If you are regularly wanting to integrate then you will want to automate. You will need to assess how often this will be necessary (when would you expect new data to come in?) to know how often the script needs to run.
						</aside>
					</section>
					<!-- Slide 48b -->
					<section data-background-image="../assets/generic/main.PNG">
						<h1> Task Scheduling </h1>
						<div class='row'>
							<div class='col'>
								<p> Microsoft has a 'Task Scheduler' which can create batch files </p>
								<p> To help with performance, scripts should be run out of hours to ensure performance is not slowed down </p>
							</div>
							<div class='col'>
								<img src='assets/session_1/schedule.PNG'>
							</div>
						</div>
						<!-- Slide 48b Notes -->
						<aside class='notes'>
							For example, you could use Microsoft&apos;s Task scheduler to plan when batch uploads should happen (and therefore when the scripts should run). Integrating data to a warehouse will often require the warehouse to be offline, so to avoid disruption this should be scheduled for outside normal working hours. 
						</aside>
					</section>
				</section>
				<!-- Slide 49 -->
				<section data-background-image="../assets/generic/section.PNG">
					<div class="wrap aligncenter">
						<span class='title'> Licenses vs Coding </span>          
					</div>
					<!-- Slide 49 Notes -->
					<aside class='notes'>
						As we have discussed, ETL and data integration has a variety of methods which range from coding it yourself manually or using a licensed software. Let's examine both.
					</aside>
				</section>
				<!-- Slide 50 -->
				<section data-background-image="../assets/generic/circle_remix.PNG">				
					<div class='wrap' style='width:max-content'>
						<p style='font-size:40px;color:#4d61f4'><b>Advantages</b> </p>
						<div class='r-hstack'>
							<div class='fragment'>
								<h4 style=color:#ff7c66;font-size:30px> License </h4>				
								<ul style='display:inline-block;text-align:left'>
									<li> Company may already have license </li>
									<li> Friendly GUI </li>
									<li> Supports various databases and formats </li>
									<li> Customer support and good documentation </li>
									<li> Easy scalability for larger datasets </li>							
								</ul>
							</div>
							<br>
							<div class='fragment'>
								<h4 style=color:#59d8a1;font-size:30px> Coding </h4>
								<ul style='display:inline-block;text-align:left'>
									<li> Easy to create if database is small</li>
									<li> Easy to install </li>
								</ul>
							</div>
						</div>
					</div>
					<!-- Slide 50 Notes -->
					<aside class='notes'>
						Ask apprentices to suggest the advantages to using a license and the advantages of coding. Run through the examples on the screen.
					</aside>
				</section>
				<!-- Slide 51 -->
				<section data-background-image="../assets/generic/circle_remix.PNG">					
					<div class='wrap' style='width:max-content'>
						<p style='font-size:40px;color:#4d61f4'><b>Disadvantages</b> </p>
						<div class='r-hstack'>
							<div class='fragment'>
								<h4 style=color:#ff7c66;font-size:30px> License </h4>				
								<ul style='display:inline-block;text-align:left'>
									<li> License costs </li>
									<li> Steep learning curve </li>					
								</ul>
							</div>
							<br>
							<div class='fragment'>
								<h4 style=color:#59d8a1;font-size:30px> Coding </h4>
								<ul style='display:inline-block;text-align:left'>
									<li> Challenging to create (especially if schema changes frequently)</li>
									<li> Developing scripts is time consuming </li>
									<li> Issues around scaling to larger datasets</li>
									<li> Requires programming expertise </li>
								</ul>
							</div>
						</div>
					</div>
					<!-- Slide 51 Notes -->
					<aside class='notes'>
						Do the same with the disadvantages
					</aside>
				</section>
				<!-- Slide 52 -->
				<section data-background-image="../assets/generic/circle_remix.PNG">
					<h1> Data Integration Softwares </h1>
					<div class="r-stack">
						<img class="fragment fade-out" data-fragment-index="0" src="assets/session_1/zapier-official.svg" width="450" height="300">
						<img class="fragment fade-out" data-fragment-index="0" src="assets/session_1/ifttt-logo.png" width="450" height="300">
						<img class="fragment fade-out" data-fragment-index="0" src="assets/session_1/automate-logo.png" width="450" height="300">
						<img class="fragment fade-out" data-fragment-index="0" src="assets/session_1/Dell_Logo.svg" width="450" height="300">
					</div>
					<!-- Slide 52 Notes -->
					<aside class='notes'>
						Run through a few examples of data integration softwares: Zapier (allows users tto integrate web applications such as Google Suite, Slack and emails), IFTTT (If This Then That- a free software that allows for automation chains), Automate.io (integrates cloud applications wihtout coding with a drag and drop interface) and Dell Boomi(another coding-lite cloud based integratin software). There are others available- check out this <a href='https://mopinion.com/data-integration-software-an-overview/'>article</a> for a bit more information on each.
					</aside>
				</section>
				<!-- Slide 53 -->
				<section data-background-image="../assets/generic/section.PNG">
					<div class="wrap aligncenter">
						<span class='title'> Master Data Management</span>          
					</div>
					<!-- Slide 53 Notes -->
					<aside class='notes'>
						We have spoken a bit today about data management and why it is important (maintaining integrity, etc). Something you should also be aware of is master data.
					</aside>
				</section>
				<!-- Slide 54 -->
				<section data-background-image="../assets/generic/fun_box.PNG">
					<p style ='color:#64abff;font-size:35px'> Important data about items in an organisation is called <u> Master Data </u> 	</p>
					<p style ='color:#64abff;font-size:35px'> This includes <u>customer and product information</u> as well as <u> organisational structure </u>	</p>
					<!-- Slide 54 Notes -->
					<aside class='notes'>
						Master data is the important data in an organisation such as customer data as well organisational structure. It is the data you need to make key business decisions and should be managed and maintained carefully. 
					</aside>
				</section>
				<!-- Slide 55 -->
				<section data-background-image="../assets/generic/fun_box.PNG">
					<p style ='color:#64abff;font-size:35px'> In business, master data management (MDM) <u>comprises the processes, governance, policies, standards and tools</u> that consistently define and <u>manage the critical data of an organisation</u> to provide a single point of reference. 	</p>
					<!-- Slide 55 Notes -->
					<aside class='notes'>
						The process of managing this data is called master data management and relates to all aspects of storing, protecting and using it as defined by the organisation. It means all the relevant information can be accessed from one location for ease.
					</aside>
				</section>
				<!-- Slide 56 -->
				<section data-background-image="../assets/generic/strike_force.PNG">
					<div class='row'>
						<div class='col'>
							<h1 style='color:#f4f4f4'> Benefits </h1>
						</div>
						<div class='col'>
							<p class='fragment'> Redundancy Elimination </p>
							<p class='fragment'> Master Data Edits </p>
							<p class='fragment'> Data Consistency </p>
							<p class='fragment'> Access Based on Role </p>
						</div>
					</div>
					<!-- Slide 56 Notes -->
					<aside class='notes'>
						The benefit of having a MDM is that everyone who needs access to this data is clear on what the rules are (or can at least easily reference them) meaning redundancy is eliminated, confidence around the data quality and knowledge about who has access and why they have access. It is important for an organisation to maintain this information for employees to avoid confusion around data useage. 
					</aside >
				</section>
				<!-- Slide 57 -->
				<section data-background-image="../assets/generic/section.PNG">
					<div class="wrap aligncenter">
						<span class='title'> Testing Strategies</span>          
					</div>
					<!-- Slide 57 Notes -->
					<aside class='notes'>
						The final section of this module covers testing strategies, in other words, how can we check that our process has worked? It is part of the validation and verification process of making sure our ETL and data integration processes have done what we expected. 
					</aside>
				</section>				
				<section>
					<!-- Slide 58a -->
					<section data-background-image="../assets/generic/fun_box.PNG">
						<div class="wrap size-50 aligncenter">
							<span style ='color:#4d61f4;font-size:100px;font-weight:bold;text-align:center'> Why do we need testing strategies? </span>
						</div>
						<!-- Slide 58a Notes -->
						<aside class='notes'>
							Ask apprentices why they think we need to test our integration processes.
						</aside>
					</section>
					<!-- Slide 58b -->
					<section data-background-image='../assets/generic/table_back.PNG'>
						<p style='font-size:35px;color:#4d61f4'> To ensure that unified data sets are:</p>
						<ul class='fragment' style='display:inline-block;text-align:left;font-size:35px'>
							<li class='fragment'> Correct </li>
							<li class='fragment'> Complete </li>
							<li class='fragment'> Up to Date </li>
						</ul>
						<!-- Slide 58b Notes -->
						<aside class='notes'>
							By testing our processes we can be confident the data in the unified set is correct, complete (no missing data or redundant values) and up to date (accurate). Keeping in mind that the purpose of integrating our data into one source is so we can perform complex analytics quickly, it is important we know the data is correct and that the processes work as intended.
						</aside>
					</section>
				</section>
				<!-- Slide 59 -->
				<section data-background-image="../assets/generic/strike_force.PNG">
					<div class='row'>
						<div class='col'>
							<h1 style='color:#f4f4f4'> Types of Testing Strategies </h1>
						</div>
						<div class='col'>
							<p class='fragment'> Technical Acceptance Testing (TAT) </p>
							<p class='fragment'> User Acceptance Testing (UAT) </p>								
							<p class='fragment'> Performance Stress Testing (PST)</p>								
						</div>
					</div>
					<!-- Slide 59 Notes -->
					<aside class='notes'>
						There are three types of testing strategy (anyone remember what they were called when we showed them earlier?). We will cover each in a bit more detail.
					</aside>
				</section>
				<!-- Slide 60 -->
				<section data-background-image="../assets/generic/strike.PNG">
					<div class='row'>
						<div class='col'>
							<img src='assets/session_1/tat.PNG'>
							<br>
							<p> Testing scripts to ensure they produce the correct output </p>
							<p> Can be done manually or by automation </p>
							<p> There are three strategies:</p>
							<ul class='fragment' style='display:inline-block;text-align:left'>
								<li class='fragment'> Unit tests </li>
								<li class='fragment'> Integration tests </li>
								<li class='fragment'> Functional tests </li>
							</ul>
						</div>
						<div class='col'>
							<h2 style='color:#f4f4f4'> Technical Acceptance Testing (TAT) </h2>
						</div>
					</div>
					<!-- Slide 60 Notes -->
					<aside class='notes'>
						The first is called Technical Acceptance Testing (TAT) which is simply testing our scripts to ensure they work as intended. You will have been doing this already when python coding, as when you write a function or control flow you will have checked to make sure it worked. If anyone has been on CodeWars you will know they run tests against your functions, which is a form of TAT.
					</aside>
				</section>
				<section>
					<!-- Slide 61a -->
					<section data-background-image="../assets/generic/main.PNG">
						<h1 style='color:#4d61f4'> TAT: Unit Tests </h1>
						<br>
						<div class='row'>
							<div class='col'>
								<p> Testing individual functions or lines of code </p>
								<p> Uses python library unittest </p>
								<p> Naming convention <code>test_xxx.py </code></p>
								<p> Run on your command line: <code> python -m unittest </code></p>
							</div>
							<div class='col'>
								<pre><code id="python_code">
								import unittest
								def fun(x):
								&nbsp;&nbsp;return x+1
									
								class MyTest(unittest.TestCase):
								&nbsp;&nbsp;def test(self):
								&nbsp;&nbsp;&nbsp;&nbsp;self.assertEqual(fun(3),4)
								</code></pre>
							</div>
						</div>
						<!-- Slide 61a Notes -->
						<aside class='notes'>
							A TAT unit test will run through a script and check that everything works as intended. To do this in python we use the unittest library and once we have defined a function we then create a use case where we tell it what the output should be. The unit test will verify that the function works correctly.
							Demonstrate this with class. In your Jupyter navigator go to New, then select Text File. Write in the code on the screen then name it test_fun.py and then save. Go back to the navigator and then go to New, then select Terminal. Check what folder the terminal is running in, and if necessary navigate to the one you saved test_fun.py in. Then type python -m unittest and run. 
						</aside>
					</section>
					<!-- Slide 61b -->
					<section data-background-image="../assets/generic/tweenies.PNG">
						<div class='row'>
							<div class='col'>
							</div>
							<div class='col'>
								<h2 style='color:#64abff'> Activity </h2>
								<br>
								<ul style='display:inline-block;text-align:left'>
									<li> Open a file in Jupyter Notebook and write a function that sums of a list of numbers </li>
									<li> Write a test case for the function in the same script and name it <code> test_sum.py</code></li>
									<li> Write a new function in a different file that averages a list of numbers </li>
									<li> Write a test case for the function in the same script and name it <code> test_average.py</code></li>
									<li> Open a terminal and run <code> python -m unittest </code></li>
								</ul>
							</div>
						</div>
						<!-- Slide 61b Notes -->
						<aside class='notes'>
							Give apprentices 10 minutes to attempt this section, test_sum.py and test_average.py have already been created for coach useage for when you go through solutions.
						</aside>
					</section>
				</section>
				<!-- Slide 62 -->
				<section data-background-image="../assets/generic/main.PNG">
					<h1 style='color:#4d61f4'> TAT: Integration Tests </h1>
					<br>
					<p> Integration tests verify that different modules or services used by your application work well together. </p>
					<p> For example, it can be testing the interaction with a database, i.e. are you able to write queries? </p>
					<!-- Slide 62 Notes -->
					<aside class='notes'>
						An integration test verifies that the different modules or services work as intended. If you connect two sources together, do they actually integrate? Does the server you connected your Tableau workbook to actually communicate? These sort of tests check the pipeline processes (like a plumber checking piping connections are sealed correctly and won't leak or block when the water flows).
					</aside>
				</section>
				<!-- Slide 63 -->
				<section data-background-image="../assets/generic/main.PNG">
					<h1 style='color:#4d61f4'> TAT: Functional Tests </h1>
					<br>
					<p> These focus on the business requirements of an application. They <u>only verify the output of an action</u> and do not check the intermediate states of the system when performing that action. </p>
					<!-- Slide 63 Notes -->
					<aside class='notes'>
						A TAT functional test verifies that the process works as intended from a business point of view. They ensure the output is what you wanted from the brief. These can be carried out by the stakeholder themselves to check the output is what they wanted. To recap: unit tests check the code/functions work, integration tests if the different software/sources interact with each other properly and functional tests the process meets the business requirement from the project brief.
					</aside>
				</section>
				<section>
					<!-- Slide 64a -->
					<section data-background-image="../assets/generic/strike.PNG">
						<div class='row'>
							<div class='col'>
								<img src='assets/session_1/uat.PNG'>
								<br>
								<p> Formal tests to verify if a report or system statisfies its business requirements </p>
								<p> Can be done manually or by automation </p>
							</div>
							<div class='col'>
								<h2 style='color:#f4f4f4'> User Acceptance Testing (UAT) </h2>
							</div>
						</div>
						<!-- Slide 64a Notes -->
						<aside class='notes'>
							A UAT checks if the process meets the business requirements (similar to a TAT functional test). The user checks the process to ensure they are satisfied it works. This can be done manually or automatically (check for key words, reports in the correct format).
						</aside>
					</section>
					<!-- Slide 64b -->
					<section data-background-image="../assets/generic/strike.PNG">
						<div class='row'>
							<div class='col'>
								<p> Answers questions like:</p>
								<ul class='fragment' style='display:inline-block;text-align:left'>
									<li class='fragment'> Does the report meet the original requirements? </li>
									<li class='fragment'> Does the report produce sensible information? </li>
									<li class='fragment'> Is the design and layout acceptable? </li>
								</ul>
							</div>
							<div class='col'>
								<h2 style='color:#f4f4f4'> User Acceptance Testing (UAT) </h2>
							</div>
						</div>
						<!-- Slide 64b Notes -->
						<aside class='notes'>
							Ask the apprentices what value these sort of tests would have. UAT's allow you to confirm you have met the business requirements and also verify the format (font, layout, colours, etc) of the end product.
						</aside>
					</section>
				</section>
				<section>
					<!-- Slide 65a -->
					<section data-background-image="../assets/generic/strike.PNG">
						<div class='row'>
							<div class='col'>
								<img src='assets/session_1/pst.PNG'>
								<br>
								<p> Focusses on validating performance characteristics of the product such as scalability and reliability </p>
								<p> They check the behaviours of the system when it is under a significant load </p>								
							</div>
							<div class='col'>
								<h2 style='color:#f4f4f4'> Performance Stress Testing (PST) </h2>
							</div>
						</div>
						<!-- Slide 65a Notes -->
						<aside class='notes'>
							Finally we have performance stress testing which checks if your process can work to scale. If hundreds of users require use of your warehouse, you don't want it breaking when they all try to access it at once. This is the equivalent of seeing how many items you can hold in a shopping bag before it breaks. If you are expecting huge amounts of users you need to ensure the system is robust enough to handle it.
						</aside>
					</section>
					<!-- Slide 65b -->
					<section data-background-image="../assets/generic/strike.PNG">
						<div class='row'>
							<div class='col'>
								<p> Tests are based on non functional requirements:</p>
								<ul class='fragment' style='display:inline-block;text-align:left'>
									<li class='fragment'> Scalability </li>
									<li class='fragment'> Reliability </li>
									<li class='fragment'> Stability </li>
									<li class='fragment'> Availability </li>
								</ul>
							</div>
							<div class='col'>
								<h2 style='color:#f4f4f4'> Performance Stress Testing (PST) </h2>
							</div>
						</div>
						<!-- Slide 65b Notes -->
						<aside class='notes'>
							Ask the apprentices what else these tests might be checking for. Apart from checking if the process can work to scale, they are also ensuring it will work reliably with little lag time when multiple users are accessing it. They also want to check that data is available quickly when requested.
						</aside>
					</section>
				</section>
				<!-- Slide 66 -->
				<section data-background-image="../assets/generic/section.PNG">
					<div class="wrap aligncenter">
						<span class='title'> Recap</span>          
					</div>
					<!-- Slide 66 Notes -->
					<aside class='notes'>
						Time to recap the day
					</aside>
				</section>
				<!-- Slide 67 -->
				<section data-background-image="../assets/generic/info_yellow.PNG">
					<div class="wrap size-60 bg-white" style='width:max-content'>
						<h1> Learning Objectives </h1>
						<ul style='display:inline-block;text-align:left'>
							<li> <b>Understand</b> concepts of Data Integration and ETL techniques </li>
							<li> <b> Explain </b> the difference between <b> Data Integration</b> and <b> Data Migration</b></li>
							<li> <b> Explore </b> different testing strategies for Data Integration</li>
						</ul>          
					</div>
					<!-- Slide 67 Notes -->
					<aside class='notes'>
						Run through learning objectives again, state how apprentices now have an understanding of what data integration is, how it works and why it is useful. In the next session you will be covering data synchronization and Gateway
					</aside>
				</section>
			</div>
		</div>
 
    <!-- Scripts -->

		<script src="../Dependencies/dist/reveal.js"></script>
		<script src="../Dependencies/plugin/notes/notes.js"></script>
		<script src="../Dependencies/plugin/markdown/markdown.js"></script>
		<script src="../Dependencies/plugin/highlight/highlight.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({				
				hash: true,
				mouseWheel:true,
				controls:true,
				slideNumber:true,
				loop:true,
				

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>
		<script src="../Dependencies/node_modules/socket.io/lib/socket.js"></script>
		<script src="../Dependencies/node_modules/reveal-notes-server/client.js"></script>
		<script type="text/javascript">
			window.onload = function(){
					var codeElement = document.getElementById('python_code');
					// Add code mirror class for coloring (default is the theme)
					codeElement.classList.add( 'cm-s-default' );
					var code = codeElement.innerText;

					codeElement.innerHTML = "";

					CodeMirror.runMode(
						code,
						'python',
						codeElement
					);
			};
			
    </script>
  </body>
  
</html>
